{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\Shivansh\\AppData\\Local\\Temp\\ipykernel_18456\\2950321141.py:11: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  telemetry = pd.read_csv('data\\PdM_telemetry.csv')  # Columns: [datetime, machineID, volt, rotate, pressure]\n",
      "C:\\Users\\Shivansh\\AppData\\Local\\Temp\\ipykernel_18456\\2950321141.py:12: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  errors = pd.read_csv('data\\PdM_errors.csv')    # Columns: [datetime, machineID, errorID]\n",
      "C:\\Users\\Shivansh\\AppData\\Local\\Temp\\ipykernel_18456\\2950321141.py:13: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  maintenance = pd.read_csv('data\\PdM_machines.csv')  # Columns: [datetime, machineID, comp]\n",
      "C:\\Users\\Shivansh\\AppData\\Local\\Temp\\ipykernel_18456\\2950321141.py:14: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  machines = pd.read_csv('data\\PdM_machines.csv')    # Columns: [machineID, model, age]\n",
      "C:\\Users\\Shivansh\\AppData\\Local\\Temp\\ipykernel_18456\\2950321141.py:15: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  failures = pd.read_csv('data\\PdM_failures.csv')    # Columns: [datetime, machineID, failure]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    175084\n",
      "         1.0       0.19      0.03      0.06       145\n",
      "\n",
      "    accuracy                           1.00    175229\n",
      "   macro avg       0.60      0.52      0.53    175229\n",
      "weighted avg       1.00      1.00      1.00    175229\n",
      "\n",
      "Accuracy: 0.9991\n",
      "ROC AUC Score: 0.7885\n",
      "\n",
      "Random Forest Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    175084\n",
      "         1.0       0.67      0.01      0.03       145\n",
      "\n",
      "    accuracy                           1.00    175229\n",
      "   macro avg       0.83      0.51      0.51    175229\n",
      "weighted avg       1.00      1.00      1.00    175229\n",
      "\n",
      "Accuracy: 0.9992\n",
      "ROC AUC Score: 0.5928\n",
      "\n",
      "Model Comparison:\n",
      "Gradient Boosting - Accuracy: 0.9991, ROC AUC: 0.7885\n",
      "Random Forest - Accuracy: 0.9992, ROC AUC: 0.5928\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "# Load your datasets (adjust file paths as necessary)\n",
    "telemetry = pd.read_csv('data\\PdM_telemetry.csv')  # Columns: [datetime, machineID, volt, rotate, pressure]\n",
    "errors = pd.read_csv('data\\PdM_errors.csv')    # Columns: [datetime, machineID, errorID]\n",
    "maintenance = pd.read_csv('data\\PdM_machines.csv')  # Columns: [datetime, machineID, comp]\n",
    "machines = pd.read_csv('data\\PdM_machines.csv')    # Columns: [machineID, model, age]\n",
    "failures = pd.read_csv('data\\PdM_failures.csv')    # Columns: [datetime, machineID, failure]\n",
    "\n",
    "# Convert datetime columns to pandas datetime\n",
    "telemetry['datetime'] = pd.to_datetime(telemetry['datetime'])\n",
    "errors['datetime'] = pd.to_datetime(errors['datetime'])\n",
    "failures['datetime'] = pd.to_datetime(failures['datetime'])\n",
    "\n",
    "# Feature engineering (example features like mean, std of telemetry)\n",
    "telemetry['volt_mean'] = telemetry.groupby('machineID')['volt'].transform('mean')\n",
    "telemetry['rotate_mean'] = telemetry.groupby('machineID')['rotate'].transform('mean')\n",
    "telemetry['pressure_mean'] = telemetry.groupby('machineID')['pressure'].transform('mean')\n",
    "telemetry['vibration_mean'] = telemetry.groupby('machineID')['vibration'].transform('mean')\n",
    "\n",
    "telemetry['volt_std'] = telemetry.groupby('machineID')['volt'].transform('std')\n",
    "telemetry['rotate_std'] = telemetry.groupby('machineID')['rotate'].transform('std')\n",
    "telemetry['pressure_std'] = telemetry.groupby('machineID')['pressure'].transform('std')\n",
    "telemetry['vibration_std'] = telemetry.groupby('machineID')['vibration'].transform('std')\n",
    "\n",
    "# Merge telemetry with machines data (using machineID as the key)\n",
    "data = pd.merge(telemetry, machines, on='machineID', how='left')\n",
    "\n",
    "# Merge telemetry with failure data (label creation)\n",
    "failures['failure'] = 1\n",
    "data = pd.merge(data, failures[['datetime', 'machineID', 'failure']], on=['datetime', 'machineID'], how='left')\n",
    "data['failure'] = data['failure'].fillna(0)\n",
    "\n",
    "# Handle categorical columns (OneHotEncoding for model and errorID)\n",
    "data = pd.get_dummies(data, columns=['model'], drop_first=True)\n",
    "errors_encoded = pd.get_dummies(errors, columns=['errorID'], drop_first=True)\n",
    "\n",
    "# Example of time since the last failure (feature engineering)\n",
    "data['time_since_last_failure'] = data.groupby('machineID')['datetime'].diff().dt.total_seconds().fillna(0)\n",
    "\n",
    "# Convert boolean columns to integers\n",
    "bool_columns = data.select_dtypes(include='bool').columns\n",
    "data[bool_columns] = data[bool_columns].astype(int)\n",
    "\n",
    "# Prepare features (X) and label (y)\n",
    "X = data.drop(columns=['datetime', 'failure', 'machineID'])\n",
    "y = data['failure']\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "numerical_cols = ['volt', 'rotate', 'pressure', 'vibration', 'volt_mean', 'rotate_mean', 'pressure_mean', 'vibration_mean', 'volt_std', 'rotate_std', 'pressure_std', 'vibration_std', 'age', 'time_since_last_failure']\n",
    "categorical_cols = [col for col in X.columns if 'model' in col or 'errorID' in col]\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_cols),\n",
    "        ('cat', SimpleImputer(strategy='most_frequent'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define pipelines for both models\n",
    "gb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "### Gradient Boosting Model ###\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_gb = gb_pipeline.predict(X_test)\n",
    "y_pred_prob_gb = gb_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the Gradient Boosting model\n",
    "print(\"Gradient Boosting Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_gb):.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred_prob_gb):.4f}\")\n",
    "\n",
    "### Random Forest Model ###\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "y_pred_prob_rf = rf_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "print(\"\\nRandom Forest Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred_prob_rf):.4f}\")\n",
    "\n",
    "# Compare Models\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"Gradient Boosting - Accuracy: {accuracy_score(y_test, y_pred_gb):.4f}, ROC AUC: {roc_auc_score(y_test, y_pred_prob_gb):.4f}\")\n",
    "print(f\"Random Forest - Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}, ROC AUC: {roc_auc_score(y_test, y_pred_prob_rf):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\Shivansh\\AppData\\Local\\Temp\\ipykernel_18456\\2135191275.py:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  data.to_csv('data\\processed_data.csv', index=False)\n"
     ]
    }
   ],
   "source": [
    "data.to_csv('data\\processed_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telemetry Columns: Index(['datetime', 'machineID', 'volt', 'rotate', 'pressure', 'vibration'], dtype='object')\n",
      "Error Logs Columns: Index(['datetime', 'machineID', 'errorID'], dtype='object')\n",
      "Maintenance Columns: Index(['machineID', 'model', 'age'], dtype='object')\n",
      "Machines Columns: Index(['machineID', 'model', 'age'], dtype='object')\n",
      "Failures Columns: Index(['datetime', 'machineID', 'failure'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "telemetry = pd.read_csv('data\\PdM_telemetry.csv')  # Columns: [datetime, machineID, volt, rotate, pressure]\n",
    "errors = pd.read_csv('data\\PdM_errors.csv')    # Columns: [datetime, machineID, errorID]\n",
    "maintenance = pd.read_csv('data\\PdM_machines.csv')  # Columns: [datetime, machineID, comp]\n",
    "machines = pd.read_csv('data\\PdM_machines.csv')    # Columns: [machineID, model, age]\n",
    "failures = pd.read_csv('data\\PdM_failures.csv')    # Columns: [datetime, machineID, failure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
